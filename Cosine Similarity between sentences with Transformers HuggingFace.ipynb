{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The sun was setting behind the mountains, painting the sky in shades of orange and pink.\",\n",
    "    \"Artificial intelligence is transforming industries by automating complex tasks.\",\n",
    "    \"Success comes to those who are willing to work hard and never give up.\",\n",
    "    \"Water boils at 100 degrees Celsius under normal atmospheric pressure.\",\n",
    "    \"As she opened the old wooden box, a mysterious glow filled the room.\",\n",
    "    \"Time is an illusion, yet it dictates every aspect of our lives.\",\n",
    "    \"I told my computer I needed a break, and now it wonâ€™t stop sending me vacation ads.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a230a0ff0c44f5a116baba7710381f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf08368382a46fda560272c0e14b9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d283c5e4a4e94aeaa0f58b3746d229c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13472cc7c71a4bc9bca59b4025a49c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340ee8ffadb544b4aa83c4411f7d6c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb1771dc6294fbfa148a5e765255249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,  2053,  1041, 11563,  2855,     2,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sentence = 'its a sunny morning'\n",
    "new_tokens =    new_tokens = tokenizer.encode_plus(example_sentence, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "new_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {'input_ids': [], 'attention_mask': []}\n",
    "\n",
    "for sentence in sentences:\n",
    "    new_tokens = tokenizer.encode_plus(sentence, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    tokens['input_ids'].append(new_tokens['input_ids'][0])\n",
    "    tokens['attention_mask'].append(new_tokens['attention_mask'][0])\n",
    "\n",
    "tokens['input_ids'] = torch.stack(tokens['input_ids'])\n",
    "tokens['attention_mask'] = torch.stack(tokens['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 2.1330e-03,  4.3467e-02, -2.4626e-04,  ...,  2.3634e-02,\n",
       "           8.8428e-02, -4.4322e-02],\n",
       "         [-7.2448e-02, -9.1777e-02, -3.2436e-02,  ...,  4.8388e-02,\n",
       "           1.8409e-01, -2.5963e-02],\n",
       "         [-8.9624e-02,  3.9373e-02,  1.7001e-02,  ...,  5.1580e-02,\n",
       "           1.1998e-01,  1.0614e-02],\n",
       "         ...,\n",
       "         [ 1.9111e-02,  1.1562e-01, -4.9137e-02,  ...,  6.7581e-02,\n",
       "           5.8653e-02,  2.5139e-02],\n",
       "         [ 1.9111e-02,  1.1562e-01, -4.9137e-02,  ...,  6.7581e-02,\n",
       "           5.8653e-02,  2.5139e-02],\n",
       "         [ 1.9111e-02,  1.1562e-01, -4.9137e-02,  ...,  6.7581e-02,\n",
       "           5.8653e-02,  2.5139e-02]],\n",
       "\n",
       "        [[-1.6499e-01,  2.3200e-03, -1.1128e-01,  ..., -3.8634e-03,\n",
       "          -9.9554e-02, -1.2559e-01],\n",
       "         [-2.3507e-01,  2.4888e-01, -2.2340e-01,  ...,  5.7779e-02,\n",
       "          -1.4258e-01, -8.7547e-02],\n",
       "         [-1.2114e-01,  3.9920e-01, -1.8274e-01,  ..., -3.9520e-03,\n",
       "          -1.7354e-01, -1.2680e-01],\n",
       "         ...,\n",
       "         [-8.8651e-02,  1.8538e-01, -1.2956e-01,  ...,  1.1247e-01,\n",
       "          -1.7994e-01, -7.8004e-02],\n",
       "         [-8.8651e-02,  1.8538e-01, -1.2956e-01,  ...,  1.1247e-01,\n",
       "          -1.7994e-01, -7.8004e-02],\n",
       "         [-8.8651e-02,  1.8538e-01, -1.2956e-01,  ...,  1.1247e-01,\n",
       "          -1.7994e-01, -7.8004e-02]],\n",
       "\n",
       "        [[ 5.4791e-02,  1.2613e-01, -5.8873e-02,  ..., -4.7002e-03,\n",
       "           1.5784e-01, -2.5526e-01],\n",
       "         [ 2.6187e-02,  5.0348e-01, -7.9937e-02,  ...,  2.3124e-02,\n",
       "           8.9861e-02, -2.1199e-01],\n",
       "         [-3.6845e-02,  2.9373e-01, -5.5425e-02,  ..., -9.2807e-02,\n",
       "           2.4235e-01, -2.1866e-01],\n",
       "         ...,\n",
       "         [ 3.9734e-03,  3.1857e-01, -6.1018e-02,  ...,  9.2319e-02,\n",
       "           1.9941e-01, -1.1283e-01],\n",
       "         [ 3.9734e-03,  3.1857e-01, -6.1018e-02,  ...,  9.2319e-02,\n",
       "           1.9941e-01, -1.1283e-01],\n",
       "         [ 3.9734e-03,  3.1857e-01, -6.1018e-02,  ...,  9.2319e-02,\n",
       "           1.9941e-01, -1.1283e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4556e-01, -2.6124e-02, -5.0696e-02,  ...,  1.8893e-02,\n",
       "          -5.6575e-02, -7.1705e-02],\n",
       "         [ 1.4175e-01, -1.9693e-01, -5.1702e-02,  ...,  8.9687e-02,\n",
       "          -7.0945e-02, -1.1136e-01],\n",
       "         [ 5.5727e-02,  5.8164e-02, -2.0976e-02,  ...,  9.3606e-02,\n",
       "          -2.0250e-01, -3.5357e-02],\n",
       "         ...,\n",
       "         [ 1.7332e-01,  8.0168e-02, -5.8388e-02,  ...,  1.3692e-01,\n",
       "          -9.8731e-02, -7.1250e-03],\n",
       "         [ 1.7332e-01,  8.0168e-02, -5.8388e-02,  ...,  1.3692e-01,\n",
       "          -9.8731e-02, -7.1250e-03],\n",
       "         [ 1.7332e-01,  8.0168e-02, -5.8388e-02,  ...,  1.3692e-01,\n",
       "          -9.8731e-02, -7.1250e-03]],\n",
       "\n",
       "        [[ 8.4096e-02,  2.1940e-01, -4.6550e-02,  ..., -1.4380e-02,\n",
       "           6.8362e-02, -9.2219e-02],\n",
       "         [ 3.5864e-02,  1.2115e-01, -9.3722e-02,  ...,  1.0331e-01,\n",
       "           2.6003e-01, -2.4628e-02],\n",
       "         [ 1.2065e-01,  1.3584e-01, -1.3461e-01,  ...,  1.6618e-01,\n",
       "           1.5163e-01, -4.3304e-02],\n",
       "         ...,\n",
       "         [ 9.8445e-02,  2.2988e-01, -7.0749e-02,  ...,  1.4570e-01,\n",
       "           4.7322e-02, -3.7000e-03],\n",
       "         [ 9.8445e-02,  2.2988e-01, -7.0749e-02,  ...,  1.4570e-01,\n",
       "           4.7322e-02, -3.7000e-03],\n",
       "         [ 9.8445e-02,  2.2988e-01, -7.0749e-02,  ...,  1.4570e-01,\n",
       "           4.7322e-02, -3.7000e-03]],\n",
       "\n",
       "        [[-5.2107e-03,  1.9114e-01, -5.6028e-02,  ...,  1.1392e-01,\n",
       "          -9.8314e-02, -3.8535e-02],\n",
       "         [ 7.2941e-03,  2.7181e-01, -5.9590e-02,  ...,  1.0030e-01,\n",
       "          -7.5523e-02, -1.0210e-01],\n",
       "         [-6.6096e-02,  1.6224e-01, -1.2810e-01,  ...,  8.1167e-02,\n",
       "          -7.2074e-02, -1.7907e-01],\n",
       "         ...,\n",
       "         [ 4.9413e-02,  3.6007e-01, -1.2003e-01,  ...,  9.6119e-02,\n",
       "          -8.1242e-02, -1.0257e-02],\n",
       "         [ 4.9413e-02,  3.6007e-01, -1.2003e-01,  ...,  9.6119e-02,\n",
       "          -8.1242e-02, -1.0257e-02],\n",
       "         [ 4.9413e-02,  3.6007e-01, -1.2003e-01,  ...,  9.6119e-02,\n",
       "          -8.1242e-02, -1.0257e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.0251,  0.0151,  0.0655,  ...,  0.0240, -0.0497, -0.1222],\n",
       "        [-0.0342, -0.0260, -0.1142,  ..., -0.0545, -0.0400, -0.0382],\n",
       "        [-0.0346,  0.0180, -0.0650,  ..., -0.0228, -0.0134,  0.0169],\n",
       "        ...,\n",
       "        [-0.1181,  0.1387,  0.0881,  ..., -0.0438, -0.0196, -0.0408],\n",
       "        [-0.0111, -0.0476, -0.0767,  ..., -0.0304, -0.0340, -0.0257],\n",
       "        [-0.0226, -0.0328, -0.1829,  ...,  0.0105, -0.0131,  0.0163]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**tokens)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1330e-03,  4.3467e-02, -2.4626e-04,  ...,  2.3634e-02,\n",
       "           8.8428e-02, -4.4322e-02],\n",
       "         [-7.2448e-02, -9.1777e-02, -3.2436e-02,  ...,  4.8388e-02,\n",
       "           1.8409e-01, -2.5963e-02],\n",
       "         [-8.9624e-02,  3.9373e-02,  1.7001e-02,  ...,  5.1580e-02,\n",
       "           1.1998e-01,  1.0614e-02],\n",
       "         ...,\n",
       "         [ 1.9111e-02,  1.1562e-01, -4.9137e-02,  ...,  6.7581e-02,\n",
       "           5.8653e-02,  2.5139e-02],\n",
       "         [ 1.9111e-02,  1.1562e-01, -4.9137e-02,  ...,  6.7581e-02,\n",
       "           5.8653e-02,  2.5139e-02],\n",
       "         [ 1.9111e-02,  1.1562e-01, -4.9137e-02,  ...,  6.7581e-02,\n",
       "           5.8653e-02,  2.5139e-02]],\n",
       "\n",
       "        [[-1.6499e-01,  2.3200e-03, -1.1128e-01,  ..., -3.8634e-03,\n",
       "          -9.9554e-02, -1.2559e-01],\n",
       "         [-2.3507e-01,  2.4888e-01, -2.2340e-01,  ...,  5.7779e-02,\n",
       "          -1.4258e-01, -8.7547e-02],\n",
       "         [-1.2114e-01,  3.9920e-01, -1.8274e-01,  ..., -3.9520e-03,\n",
       "          -1.7354e-01, -1.2680e-01],\n",
       "         ...,\n",
       "         [-8.8651e-02,  1.8538e-01, -1.2956e-01,  ...,  1.1247e-01,\n",
       "          -1.7994e-01, -7.8004e-02],\n",
       "         [-8.8651e-02,  1.8538e-01, -1.2956e-01,  ...,  1.1247e-01,\n",
       "          -1.7994e-01, -7.8004e-02],\n",
       "         [-8.8651e-02,  1.8538e-01, -1.2956e-01,  ...,  1.1247e-01,\n",
       "          -1.7994e-01, -7.8004e-02]],\n",
       "\n",
       "        [[ 5.4791e-02,  1.2613e-01, -5.8873e-02,  ..., -4.7002e-03,\n",
       "           1.5784e-01, -2.5526e-01],\n",
       "         [ 2.6187e-02,  5.0348e-01, -7.9937e-02,  ...,  2.3124e-02,\n",
       "           8.9861e-02, -2.1199e-01],\n",
       "         [-3.6845e-02,  2.9373e-01, -5.5425e-02,  ..., -9.2807e-02,\n",
       "           2.4235e-01, -2.1866e-01],\n",
       "         ...,\n",
       "         [ 3.9734e-03,  3.1857e-01, -6.1018e-02,  ...,  9.2319e-02,\n",
       "           1.9941e-01, -1.1283e-01],\n",
       "         [ 3.9734e-03,  3.1857e-01, -6.1018e-02,  ...,  9.2319e-02,\n",
       "           1.9941e-01, -1.1283e-01],\n",
       "         [ 3.9734e-03,  3.1857e-01, -6.1018e-02,  ...,  9.2319e-02,\n",
       "           1.9941e-01, -1.1283e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4556e-01, -2.6124e-02, -5.0696e-02,  ...,  1.8893e-02,\n",
       "          -5.6575e-02, -7.1705e-02],\n",
       "         [ 1.4175e-01, -1.9693e-01, -5.1702e-02,  ...,  8.9687e-02,\n",
       "          -7.0945e-02, -1.1136e-01],\n",
       "         [ 5.5727e-02,  5.8164e-02, -2.0976e-02,  ...,  9.3606e-02,\n",
       "          -2.0250e-01, -3.5357e-02],\n",
       "         ...,\n",
       "         [ 1.7332e-01,  8.0168e-02, -5.8388e-02,  ...,  1.3692e-01,\n",
       "          -9.8731e-02, -7.1250e-03],\n",
       "         [ 1.7332e-01,  8.0168e-02, -5.8388e-02,  ...,  1.3692e-01,\n",
       "          -9.8731e-02, -7.1250e-03],\n",
       "         [ 1.7332e-01,  8.0168e-02, -5.8388e-02,  ...,  1.3692e-01,\n",
       "          -9.8731e-02, -7.1250e-03]],\n",
       "\n",
       "        [[ 8.4096e-02,  2.1940e-01, -4.6550e-02,  ..., -1.4380e-02,\n",
       "           6.8362e-02, -9.2219e-02],\n",
       "         [ 3.5864e-02,  1.2115e-01, -9.3722e-02,  ...,  1.0331e-01,\n",
       "           2.6003e-01, -2.4628e-02],\n",
       "         [ 1.2065e-01,  1.3584e-01, -1.3461e-01,  ...,  1.6618e-01,\n",
       "           1.5163e-01, -4.3304e-02],\n",
       "         ...,\n",
       "         [ 9.8445e-02,  2.2988e-01, -7.0749e-02,  ...,  1.4570e-01,\n",
       "           4.7322e-02, -3.7000e-03],\n",
       "         [ 9.8445e-02,  2.2988e-01, -7.0749e-02,  ...,  1.4570e-01,\n",
       "           4.7322e-02, -3.7000e-03],\n",
       "         [ 9.8445e-02,  2.2988e-01, -7.0749e-02,  ...,  1.4570e-01,\n",
       "           4.7322e-02, -3.7000e-03]],\n",
       "\n",
       "        [[-5.2107e-03,  1.9114e-01, -5.6028e-02,  ...,  1.1392e-01,\n",
       "          -9.8314e-02, -3.8535e-02],\n",
       "         [ 7.2941e-03,  2.7181e-01, -5.9590e-02,  ...,  1.0030e-01,\n",
       "          -7.5523e-02, -1.0210e-01],\n",
       "         [-6.6096e-02,  1.6224e-01, -1.2810e-01,  ...,  8.1167e-02,\n",
       "          -7.2074e-02, -1.7907e-01],\n",
       "         ...,\n",
       "         [ 4.9413e-02,  3.6007e-01, -1.2003e-01,  ...,  9.6119e-02,\n",
       "          -8.1242e-02, -1.0257e-02],\n",
       "         [ 4.9413e-02,  3.6007e-01, -1.2003e-01,  ...,  9.6119e-02,\n",
       "          -8.1242e-02, -1.0257e-02],\n",
       "         [ 4.9413e-02,  3.6007e-01, -1.2003e-01,  ...,  9.6119e-02,\n",
       "          -8.1242e-02, -1.0257e-02]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = outputs.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 512, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic concept behind pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = tokens['attention_mask']\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 512, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_attention_mask = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "resized_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1330e-03,  4.3467e-02, -2.4626e-04,  ...,  2.3634e-02,\n",
       "           8.8428e-02, -4.4322e-02],\n",
       "         [-7.2448e-02, -9.1777e-02, -3.2436e-02,  ...,  4.8388e-02,\n",
       "           1.8409e-01, -2.5963e-02],\n",
       "         [-8.9624e-02,  3.9373e-02,  1.7001e-02,  ...,  5.1580e-02,\n",
       "           1.1998e-01,  1.0614e-02],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.6499e-01,  2.3200e-03, -1.1128e-01,  ..., -3.8634e-03,\n",
       "          -9.9554e-02, -1.2559e-01],\n",
       "         [-2.3507e-01,  2.4888e-01, -2.2340e-01,  ...,  5.7779e-02,\n",
       "          -1.4258e-01, -8.7547e-02],\n",
       "         [-1.2114e-01,  3.9920e-01, -1.8274e-01,  ..., -3.9520e-03,\n",
       "          -1.7354e-01, -1.2680e-01],\n",
       "         ...,\n",
       "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[ 5.4791e-02,  1.2613e-01, -5.8873e-02,  ..., -4.7002e-03,\n",
       "           1.5784e-01, -2.5526e-01],\n",
       "         [ 2.6187e-02,  5.0348e-01, -7.9937e-02,  ...,  2.3124e-02,\n",
       "           8.9861e-02, -2.1199e-01],\n",
       "         [-3.6845e-02,  2.9373e-01, -5.5425e-02,  ..., -9.2807e-02,\n",
       "           2.4235e-01, -2.1866e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4556e-01, -2.6124e-02, -5.0696e-02,  ...,  1.8893e-02,\n",
       "          -5.6575e-02, -7.1705e-02],\n",
       "         [ 1.4175e-01, -1.9693e-01, -5.1702e-02,  ...,  8.9687e-02,\n",
       "          -7.0945e-02, -1.1136e-01],\n",
       "         [ 5.5727e-02,  5.8164e-02, -2.0976e-02,  ...,  9.3606e-02,\n",
       "          -2.0250e-01, -3.5357e-02],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[ 8.4096e-02,  2.1940e-01, -4.6550e-02,  ..., -1.4380e-02,\n",
       "           6.8362e-02, -9.2219e-02],\n",
       "         [ 3.5864e-02,  1.2115e-01, -9.3722e-02,  ...,  1.0331e-01,\n",
       "           2.6003e-01, -2.4628e-02],\n",
       "         [ 1.2065e-01,  1.3584e-01, -1.3461e-01,  ...,  1.6618e-01,\n",
       "           1.5163e-01, -4.3304e-02],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "        [[-5.2107e-03,  1.9114e-01, -5.6028e-02,  ...,  1.1392e-01,\n",
       "          -9.8314e-02, -3.8535e-02],\n",
       "         [ 7.2941e-03,  2.7181e-01, -5.9590e-02,  ...,  1.0030e-01,\n",
       "          -7.5523e-02, -1.0210e-01],\n",
       "         [-6.6096e-02,  1.6224e-01, -1.2810e-01,  ...,  8.1167e-02,\n",
       "          -7.2074e-02, -1.7907e-01],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "          -0.0000e+00, -0.0000e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_embedding = embeddings * resized_attention_mask\n",
    "masked_embedding.shape\n",
    "masked_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8219, -0.7590, -0.1556,  ...,  0.7899,  2.1785, -0.0442],\n",
       "        [-1.1174,  2.5114, -2.6329,  ...,  0.6614, -1.7199, -1.3346],\n",
       "        [ 0.8112,  3.9957, -0.9098,  ..., -0.3844,  3.3705, -2.4583],\n",
       "        ...,\n",
       "        [ 2.7252, -0.8334,  0.0582,  ...,  1.1797, -1.0109,  0.0286],\n",
       "        [ 1.5115,  2.9006, -1.2105,  ...,  0.6317,  2.6627, -0.9313],\n",
       "        [ 0.2614,  5.4016, -2.2521,  ...,  2.5155, -1.9161, -0.1234]],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_mask_embeddings = torch.sum(masked_embedding, 1)\n",
    "summed_mask_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 20., 20.,  ..., 20., 20., 20.],\n",
       "        [14., 14., 14.,  ..., 14., 14., 14.],\n",
       "        [17., 17., 17.,  ..., 17., 17., 17.],\n",
       "        ...,\n",
       "        [17., 17., 17.,  ..., 17., 17., 17.],\n",
       "        [18., 18., 18.,  ..., 18., 18., 18.],\n",
       "        [23., 23., 23.,  ..., 23., 23., 23.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_one_in_mask_tensor = torch.clamp(resized_attention_mask.sum(1), min=1e-9)\n",
    "count_of_one_in_mask_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 768])\n",
      "torch.Size([7, 768])\n"
     ]
    }
   ],
   "source": [
    "print(summed_mask_embeddings.shape)\n",
    "print(count_of_one_in_mask_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pooled = summed_mask_embeddings / count_of_one_in_mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate cosine similarity for sentence 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01878126,  0.03184425,  0.06315354,  0.24879582,  0.11225773,\n",
       "        -0.00982075]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "cosine_similarity([mean_pooled[0]], mean_pooled[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Itachi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
