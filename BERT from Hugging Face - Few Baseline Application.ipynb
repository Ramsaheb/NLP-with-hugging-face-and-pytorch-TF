{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '2025 will be ours'\n",
    "\n",
    "encoding = tokenizer.encode_plus(text, add_special_tokens=True, padding='max_length', truncation=True, \n",
    "                                 return_attention_mask = True, return_tensors='pt')\n",
    "\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = encoding['input_ids'][0]\n",
    "attention_mask = encoding['attention_mask'][0]\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForNextSentencePrediction, BertForQuestionAnswering\n",
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Indian city known for the Taj Mahal is \" + tokenizer.mask_token + \".\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = torch.where(encoding['input_ids'][0] == tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model output\n",
    "with torch.no_grad():\n",
    "    output = model(**encoding)\n",
    "logits = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_word = softmax[0, mask_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = torch.topk(mask_word, 10, dim=1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian city known for the Taj Mahal is mumbai.\n",
      "The Indian city known for the Taj Mahal is delhi.\n",
      "The Indian city known for the Taj Mahal is bangalore.\n",
      "The Indian city known for the Taj Mahal is pune.\n",
      "The Indian city known for the Taj Mahal is jaipur.\n",
      "The Indian city known for the Taj Mahal is kolkata.\n",
      "The Indian city known for the Taj Mahal is hyderabad.\n",
      "The Indian city known for the Taj Mahal is chennai.\n",
      "The Indian city known for the Taj Mahal is agra.\n",
      "The Indian city known for the Taj Mahal is ahmedabad.\n"
     ]
    }
   ],
   "source": [
    "for token in top_10:\n",
    "    word = tokenizer.decode([token], skip_special_tokens=True)\n",
    "    new_sentence = text.replace(tokenizer.mask_token, word)\n",
    "    print(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'I came back from clg at evening'\n",
    "next_sentence = 'I started to watch webseries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9987e-01, 1.2635e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(prompt, next_sentence, return_tensors='pt')\n",
    "outputs = model(**encoding)[0]\n",
    "softmax = F.softmax(outputs, dim=1)\n",
    "\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quetion answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6628468deda64f0da22b4db359d751db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/302 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da33a22524b420a840fb9d93fc3092e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753ade9619664754b32505e7a7f23b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985e73e55452470b894fe318d6b4092f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('deepset/bert-base-uncased-squad2')\n",
    "model = BertForQuestionAnswering.from_pretrained('deepset/bert-base-uncased-squad2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Question = \"What is the historical significance of the Taj Mahal, and who was responsible for its construction?\"\n",
    "context = \"\"\"The Taj Mahal, one of the most famous monuments in the world, was commissioned in 1632 by the Mughal Emperor Shah Jahan \n",
    "in memory of his favorite wife, Mumtaz Mahal. Located in Agra, India, it stands as a symbol of eternal love and is recognized for its \n",
    "stunning Mughal architecture. The construction took approximately 20 years, employing thousands of artisans and laborers. \n",
    "Its white marble structure is adorned with intricate carvings, calligraphy, and semi-precious stones. \n",
    "The Taj Mahal is a UNESCO World Heritage Site and attracts millions of tourists every year. \n",
    "It represents the artistic and cultural zenith of the Mughal Empire and is often considered one of the New Seven Wonders of the World.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  2003,  1996,  3439,  7784,  1997,  1996, 11937,  3501,\n",
       "         27913,  1010,  1998,  2040,  2001,  3625,  2005,  2049,  2810,  1029,\n",
       "           102,  1996, 11937,  3501, 27913,  1010,  2028,  1997,  1996,  2087,\n",
       "          3297, 10490,  1999,  1996,  2088,  1010,  2001,  4837,  1999, 28216,\n",
       "          2011,  1996, 17877,  3750,  7890, 14855,  4819,  1999,  3638,  1997,\n",
       "          2010,  5440,  2564,  1010, 12954,  2696,  2480, 27913,  1012,  2284,\n",
       "          1999, 29542,  1010,  2634,  1010,  2009,  4832,  2004,  1037,  6454,\n",
       "          1997, 10721,  2293,  1998,  2003,  3858,  2005,  2049, 14726, 17877,\n",
       "          4294,  1012,  1996,  2810,  2165,  3155,  2322,  2086,  1010, 15440,\n",
       "          5190,  1997, 26818,  1998, 23428,  1012,  2049,  2317,  7720,  3252,\n",
       "          2003, 19189,  2007, 17796, 22838,  1010,  2655, 23132,  1010,  1998,\n",
       "          4100,  1011,  9062,  6386,  1012,  1996, 11937,  3501, 27913,  2003,\n",
       "          1037, 12239,  2088,  4348,  2609,  1998, 17771,  8817,  1997,  9045,\n",
       "          2296,  2095,  1012,  2009,  5836,  1996,  6018,  1998,  3451, 28672,\n",
       "          1997,  1996, 17877,  3400,  1998,  2003,  2411,  2641,  2028,  1997,\n",
       "          1996,  2047,  2698, 16278,  1997,  1996,  2088,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = tokenizer(Question, context, return_tensors='pt')\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mumtaz mahal'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_input)\n",
    "\n",
    "answer_start_index = outputs.start_logits.argmax()\n",
    "answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "predict_answer_tokens = tokenized_input.input_ids[0, answer_start_index:answer_end_index+1]\n",
    "tokenizer.decode(predict_answer_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Itachi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
